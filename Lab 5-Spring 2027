{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "###### Follow the instructions given in comments prefixed with ## and write your code below that.\n",
    "###### Also fill the partial code in given blanks. \n",
    "###### Don't make any changes to the rest part of the codes\n",
    "\n",
    "### Answer the questions given at the end of this notebook within your report.\n",
    "\n",
    "### You would need to submit your GitHub repository link. Refer to the PDF document for the instructions and details.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Reading the image plaksha_Faculty.jpg\n",
    "img=cv2.imread(\"Plaksha_Faculty.jpg\")\n",
    "  \n",
    "## Convert the image to grayscale\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  \n",
    "# Loading the required haar-cascade xml classifier file\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+\"haarcascade_frontalface_default.xml\")\n",
    "  \n",
    "# Applying the face detection method on the grayscale image. \n",
    "## Change the parameters for better detection of faces in your case.\n",
    "faces_rect = face_cascade.detectMultiScale(gray_img, 1.05, 4, minSize=(25,25), maxSize=(50,50))\n",
    "print(\"Number of faces detected:\", len(faces_rect))\n",
    "\n",
    " \n",
    "# Define the text and font parameters\n",
    "text = \"Dtetected Faces\" ## The text you want to write\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  ## Font type\n",
    "font_scale = 0.5  ## Font scale factor\n",
    "font_color = (0,0,255)  ## Text color in BGR format (here, it's red)\n",
    "font_thickness = 1  ## Thickness of the text\n",
    "\n",
    "  \n",
    "# Iterating through rectangles of detected faces\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    # Use cv2.putText to add the text to the image, Use text, font, font_scale, font_color, font_thickness here\n",
    "    cv2.putText(img, text, (x, y-10), font, font_scale, font_color, font_thickness)\n",
    "    \n",
    "## Display the image and window title should be \"Total number of face detected are #\" \n",
    "cv2.imwrite(\"image1.jpg\", img)\n",
    "plt.savefig(\"face_cluster.png\", dpi=300, bbox_inches=\"tight\")\n",
    "cv2.imshow(f\"Total number of face detected are {len(faces_rect)}\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "# Extract face region features (Hue and Saturation)\n",
    "img_hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV) ## call the img and convert it from BGR to HSV and store in img_hsv\n",
    "hue_saturation = []\n",
    "face_images = []  # To store detected face images\n",
    "\n",
    "for (x, y, w, h) in faces_rect:\n",
    "    face = img_hsv[y:y + h, x:x + w]\n",
    "    hue = np.mean(face[:, :, 0])\n",
    "    saturation = np.mean(face[:, :, 1])\n",
    "    hue_saturation.append((hue, saturation))\n",
    "    face_images.append(face)\n",
    "\n",
    "hue_saturation = np.array(hue_saturation)\n",
    "\n",
    "## Perform k-Means clustering on hue_saturation and store in kmeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(hue_saturation)\n",
    "#centroids = kmeans.cluster_centers_\n",
    "#labels = kmeans.labels_\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the clustered faces with custom markers\n",
    "for i, (x,y,w,h ) in enumerate(faces_rect):\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
    "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1])\n",
    "    \n",
    "\n",
    "plt.xlabel(\"Hue\")\n",
    "plt.ylabel(\"Saturation\")\n",
    "plt.title(\"K-Means Clustering of Faces based on Hue & Saturation\")\n",
    "plt.savefig(\"face_cluster1.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store legend labels\n",
    "legend_labels = []\n",
    "\n",
    "# Create lists to store points for each cluster\n",
    "cluster_0_points = []\n",
    "cluster_1_points = []\n",
    "\n",
    "# Your code for scatter plot goes here\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i, (x, y, w, h) in enumerate(faces_rect):\n",
    "    if kmeans.labels_[i] == 0:\n",
    "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "    else:\n",
    "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "\n",
    "\n",
    "cluster_0_points = np.array(cluster_0_points)\n",
    "# Plot points for cluster 0 in green\n",
    "plt.scatter(cluster_0_points[:, 0],cluster_0_points[:, 1],color='green',label='Cluster 0')\n",
    "\n",
    "cluster_1_points = np.array(cluster_1_points)\n",
    "# Plot points for cluster 1 in blue\n",
    "plt.scatter(cluster_1_points[:, 0],cluster_1_points[:, 1],color='blue',label='Cluster 1')\n",
    "\n",
    "# Calculate and plot centroids\n",
    "centroid_0 = np.mean(cluster_0_points, axis=0)\n",
    "centroid_1 = np.mean(cluster_1_points, axis=0)\n",
    " \n",
    "plt.scatter(centroid_0[0], centroid_0[1],color='black',marker='X',s=200,label='Centroid 0')\n",
    "\n",
    "plt.scatter(centroid_1[0], centroid_1[1],color='red',marker='X',s=200,label='Centroid 1')\n",
    "plt.xlabel(\"Hue\")\n",
    "plt.ylabel(\"Saturation\")\n",
    "plt.title(\"K-Means Clustering (Hue vs Saturation)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"kmeans_clustering.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the class of the template image 'Dr_Shashi_Tharoor.jpg' using cv2 and store it in template_img\n",
    "template_img =cv2.imread('Dr_Shashi_Tharoor.jpg')\n",
    "# Detect face  in the template image after converting it to gray and store it in template_faces\n",
    "gray_template = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "template_faces = face_cascade.detectMultiScale(gray_template, 1.3, 5)\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "for (x, y, w, h) in template_faces:\n",
    "    cv2.rectangle(template_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "cv2.imwrite(\"template.jpg\",template_img)\n",
    "cv2.imshow(\"Detected Face\", template_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the template image to HSV color space and store it in template_hsv\n",
    "template_hsv = cv2.cvtColor(template_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Extemplate_hue = np.mean(template_hsv[:, :, 0])\n",
    "template_hue = np.mean(template_hsv[:, :, 0])\n",
    "template_saturation = np.mean(template_hsv[:, :, 1])\n",
    "\n",
    "# Predict the cluster label for the template image and store it in template_label\n",
    "template_label = kmeans.predict([[template_hue, template_saturation]])[0]\n",
    "\n",
    "# Create a figure and axis for visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the clustered faces with custom markers (similar to previous code)\n",
    "for i, (x, y, w, h) in enumerate(faces_rect):\n",
    "    color = 'red' if kmeans.labels_[i] == 0 else 'blue'\n",
    "    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n",
    "    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n",
    "    ax.add_artist(ab)\n",
    "    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1], 'o', markersize=5, color=color)\n",
    "\n",
    "# Plot the template image in the respective cluster\n",
    "if template_label == 0:\n",
    "    color = 'red'\n",
    "else:\n",
    "    color = 'blue'\n",
    "im = OffsetImage(cv2.cvtColor(cv2.resize(template_img, (20, 20)), cv2.COLOR_BGR2RGB))\n",
    "ab = AnnotationBbox(im, (template_hue, template_saturation), frameon=False, pad=0)\n",
    "ax.add_artist(ab)\n",
    "\n",
    "plt.xlabel(\"Hue\")\n",
    "plt.ylabel(\"Saturation\")\n",
    "plt.title(\"Clustered Faces with Template Image\")\n",
    "plt.savefig(\"faceclustering_template_image\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store legend labels\n",
    "legend_labels = []\n",
    "\n",
    "# Create lists to store points for each cluster\n",
    "cluster_0_points = []\n",
    "cluster_1_points = []\n",
    "\n",
    "# Your code for scatter plot goes here\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i, (x, y, w, h) in enumerate(faces_rect):\n",
    "    if kmeans.labels_[i] == 0:\n",
    "        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "    else:\n",
    "        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n",
    "\n",
    "# Plot points for cluster 0 in green\n",
    "cluster_0_points = np.array(cluster_0_points)\n",
    "plt.scatter(cluster_0_points[:, 0],cluster_0_points[:, 1],c='green', label='Cluster 0')\n",
    "\n",
    "# Plot points for cluster 1 in blue\n",
    "cluster_1_points = np.array(cluster_1_points)\n",
    "plt.scatter(cluster_1_points[:, 0],cluster_1_points[:, 1],c='blue', label='Cluster 1')\n",
    "\n",
    "# Calculate and plot centroids for both the clusters\n",
    "centroid_0 = np.mean(cluster_0_points, axis=0)\n",
    "centroid_1 = np.mean(cluster_1_points, axis=0)\n",
    "\n",
    "# Plot centroid 0\n",
    "plt.scatter(centroid_0[0],centroid_0[1],c='black', marker='X', s=200, label='Centroid 0')\n",
    "\n",
    "# Plot centroid 1\n",
    "plt.scatter(centroid_1[0],centroid_1[1],c='red', marker='X', s=200, label='Centroid 1')\n",
    "plt.plot(template_hue, template_saturation, marker='o', c= 'violet',markersize= 10, label=' Class ?' )\n",
    "\n",
    "plt.xlabel(\"Hue\")\n",
    "plt.ylabel(\"Saturation\")\n",
    "plt.title(\"KMeans Clustering with Template Classification\")\n",
    "plt.savefig(\"faceclustering_template\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "## Answer the following questions within your report:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are the common distance metrics used in distance-based classification algorithms?\n",
    "Common distance metrics include Euclidean, Manhattan, Chebyshev, and Cosine distance. The choice depends on the type of data (continuous, high-dimensional, or directional data).\n",
    "\n",
    "### 2. What are some real-world applications of distance-based classification algorithms?\n",
    "They are widely used in face recognition, image classification, handwritten digit recognition, recommendation systems, and medical diagnosis, where similarity between data points determines classification.\n",
    "\n",
    "### 3. Explain various distance metrics.\n",
    "Euclidean distance measures straight-line distance and works well for continuous data.\n",
    "Manhattan distance sums absolute differences and is useful for grid-like paths.\n",
    "Chebyshev distance takes the maximum coordinate difference.\n",
    "Cosine distance measures angular similarity, useful in text and high-dimensional data.\n",
    "\n",
    "### 4. What is the role of cross-validation in model performance?\n",
    "Cross-validation evaluates how well a model generalizes to unseen data, helps select optimal hyperparameters (like K in KNN), reduces overfitting, and provides a more reliable estimate of model accuracy.\n",
    "\n",
    "### 5. Explain variance and bias in terms of KNN.\n",
    "In KNN, a small K leads to low bias but high variance (overfitting), while a large K increases bias but reduces variance (underfitting). Choosing the right K balances the biasâ€“variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
